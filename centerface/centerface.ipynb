{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/AndrewZhaoLuo/CenterFaceTVMDemo/blob/main/python_demo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install opencv-python\n",
    "# %pip install Cython\n",
    "# %pip install onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /home/vin/.conda/envs/py38-tvm/lib/python3.8/site-packages (9.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from scripts import centerface_utils\n",
    "import cv2\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TARGET_WIDTH = 640\n",
    "TARGET_HEIGHT = 640\n",
    "TARGET_FPS = 30\n",
    "\n",
    "\n",
    "class CameraDemo:\n",
    "    \"\"\"Multi-threaded python centerface detection demo.\"\"\"\n",
    "\n",
    "    def __init__(self, runner: centerface_utils.CenterFaceNoDetection) -> None:\n",
    "        self.keep_going = True\n",
    "        self.runner = runner\n",
    "\n",
    "    def capture_frame(self, cap, queue):\n",
    "        \"\"\"Thread function which captures data from webcam and places into queue\"\"\"\n",
    "        prev = 0\n",
    "        cur = 0\n",
    "        while self.keep_going:\n",
    "            cur = time.time()\n",
    "            _, img = cap.read()\n",
    "            if (cur - prev) >= 1.0 / TARGET_FPS:\n",
    "                prev = cur\n",
    "                queue.put(img)\n",
    "\n",
    "    def process_frame(\n",
    "        self, runner, processing_func, input_queue, output_queue, threshold\n",
    "    ):\n",
    "        \"\"\"Thread function which detects and overlays results, add it to queue for rendering\"\"\"\n",
    "        while self.keep_going:\n",
    "            if input_queue.empty():\n",
    "                continue\n",
    "            frame = input_queue.get()\n",
    "            frame = processing_func(frame)\n",
    "\n",
    "            np_array = cv2.dnn.blobFromImage(\n",
    "                frame,\n",
    "                scalefactor=1.0,\n",
    "                size=(TARGET_WIDTH, TARGET_HEIGHT),\n",
    "                mean=(0, 0, 0),\n",
    "                swapRB=True,\n",
    "                crop=True,\n",
    "            )\n",
    "            start = time.time()\n",
    "            detections, landmarks = runner(\n",
    "                np_array, TARGET_HEIGHT, TARGET_WIDTH, threshold=threshold\n",
    "            )\n",
    "            end = time.time()\n",
    "            print(f\"Processing frame too {(end - start) * 1000} ms\")\n",
    "\n",
    "            # Draw predictions and show frame\n",
    "            for det in detections:\n",
    "                boxes, _ = det[:4], det[4]\n",
    "                cv2.rectangle(\n",
    "                    frame,\n",
    "                    (int(boxes[0]), int(boxes[1])),\n",
    "                    (int(boxes[2]), int(boxes[3])),\n",
    "                    (2, 255, 0),\n",
    "                    3,\n",
    "                )\n",
    "            for lm in landmarks:\n",
    "                for i in range(0, 5):\n",
    "                    cv2.circle(\n",
    "                        frame, (int(lm[i * 2]), int(lm[i * 2 + 1])), 4, (0, 0, 255), -1\n",
    "                    )\n",
    "\n",
    "            output_queue.put(frame)\n",
    "\n",
    "    def run(self, threshold=0.5):\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        cap_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "        cap_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "        # Doesn't seem to do anything :/\n",
    "        # cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)\n",
    "\n",
    "        cap_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print(\"* Capture width:\", cap_width)\n",
    "        print(\"* Capture height:\", cap_height)\n",
    "        print(\"* Capture FPS:\", cap_fps)\n",
    "\n",
    "        _, frame = cap.read()\n",
    "\n",
    "        # assume w > h\n",
    "        h, w = frame.shape[:2]\n",
    "        scale = TARGET_WIDTH / h\n",
    "        new_width = int(scale * w)\n",
    "        new_height = int(scale * h)\n",
    "\n",
    "        # For centercrop\n",
    "        left = (new_width - TARGET_WIDTH) // 2\n",
    "        top = (new_height - TARGET_HEIGHT) // 2\n",
    "        right = (new_width + TARGET_WIDTH) // 2\n",
    "        bottom = (new_height + TARGET_HEIGHT) // 2\n",
    "\n",
    "        # initial queue for webcam data\n",
    "        frames_queue = queue.Queue(maxsize=0)\n",
    "\n",
    "        # queue after we've streamed it to real-time feed\n",
    "        ready_for_processing_queue = queue.Queue(maxsize=0)\n",
    "\n",
    "        # queue for processed frames with prediction overlays\n",
    "        processed_frames_queue = queue.Queue(maxsize=0)\n",
    "\n",
    "        # start thread to capture data from webcam\n",
    "        capture_thread = Thread(\n",
    "            target=self.capture_frame,\n",
    "            args=(\n",
    "                cap,\n",
    "                frames_queue,\n",
    "            ),\n",
    "            daemon=True,\n",
    "        )\n",
    "        capture_thread.start()\n",
    "\n",
    "        def processing_func(cv2_frame):\n",
    "            # Resize and center crop frame\n",
    "            frame = cv2.resize(cv2_frame, (new_width, new_height))\n",
    "            frame = frame[top:bottom, left:right]\n",
    "            return frame\n",
    "\n",
    "        # start thread to process images with model\n",
    "        processing_thread = Thread(\n",
    "            target=self.process_frame,\n",
    "            args=(\n",
    "                self.runner,\n",
    "                processing_func,\n",
    "                ready_for_processing_queue,\n",
    "                processed_frames_queue,\n",
    "                threshold,\n",
    "            ),\n",
    "            daemon=True,\n",
    "        )\n",
    "        processing_thread.start()\n",
    "\n",
    "        while self.keep_going:\n",
    "            if not frames_queue.empty():\n",
    "                img_real_time = frames_queue.get()\n",
    "                if img_real_time is not None:\n",
    "                    cv2.imshow(\"realtime\", img_real_time)\n",
    "                    ready_for_processing_queue.put(img_real_time)\n",
    "\n",
    "            if not processed_frames_queue.empty():\n",
    "                img_processed = processed_frames_queue.get()\n",
    "                if img_processed is not None:\n",
    "                    cv2.imshow(\"predicted\", img_processed)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                self.keep_going = False\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        capture_thread.join()\n",
    "        processing_thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvm_runner_fp16 = centerface_utils.CenterFaceTVM(\n",
    "    \n",
    ")\n",
    "\n",
    "demo = CameraDemo(tvm_runner_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  4: TVMFuncCall\n  3: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>::AssignTypedLambda<tvm::runtime::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#5}>(tvm::runtime::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  2: tvm::runtime::RPCWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  1: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)> const&)\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<TVMFuncCreateFromCFunc::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) [clone .cold]\n  File \"/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 81, in cfun\n    rv = local_pyfunc(*pyargs)\n  File \"/opt/tvm/python/tvm/rpc/server.py\", line 79, in load_module\n    m = _load_module(path)\n  File \"/opt/tvm/python/tvm/runtime/module.py\", line 607, in load_module\n    return _ffi_api.ModuleLoadFromFile(path, fmt)\n  File \"/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 237, in __call__\n    raise get_last_ffi_error()\n  5: TVMFuncCall\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>::AssignTypedLambda<tvm::runtime::Module (*)(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>(tvm::runtime::Module (*)(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::runtime::Module::LoadFromFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  1: tvm::runtime::CreateDSOLibraryObject(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  0: tvm::runtime::DSOLibrary::Load(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n  File \"../src/runtime/dso_library.cc\", line 119\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (lib_handle_ != nullptr) is false: Failed to load dynamic shared library /tmp/tmpmcrvfgqs/mod.so /tmp/tmpmcrvfgqs/mod.so: invalid ELF header",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/N/10-prj/optimi/tvm/centerface/centerface.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=0'>1</a>\u001b[0m onnx_runner \u001b[39m=\u001b[39m centerface_utils\u001b[39m.\u001b[39mCenterFaceOnnx(\u001b[39m\"\u001b[39m\u001b[39mmodels/centerface-optimized.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=1'>2</a>\u001b[0m tvm_runner_fp32 \u001b[39m=\u001b[39m centerface_utils\u001b[39m.\u001b[39;49mCenterFaceTVM(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcompiled_packages/centerface_autoscheduler_30000kt_fp32_llvm.tar\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=4'>5</a>\u001b[0m tvm_runner_fp16 \u001b[39m=\u001b[39m centerface_utils\u001b[39m.\u001b[39mCenterFaceTVM(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_packages/centerface_autoscheduler_30000kt_fp16_llvm.tar\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/N/10-prj/optimi/tvm/centerface/centerface.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m dummy_runner \u001b[39m=\u001b[39m centerface_utils\u001b[39m.\u001b[39mCenterFaceNoDetection()\n",
      "File \u001b[0;32m/N/10-prj/optimi/tvm/centerface/scripts/centerface_utils.py:206\u001b[0m, in \u001b[0;36mCenterFaceTVM.__init__\u001b[0;34m(self, package_path)\u001b[0m\n\u001b[1;32m    204\u001b[0m package \u001b[39m=\u001b[39m TVMCPackage(package_path)\n\u001b[1;32m    205\u001b[0m session\u001b[39m.\u001b[39mupload(package\u001b[39m.\u001b[39mlib_path)\n\u001b[0;32m--> 206\u001b[0m lib \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39;49mload_module(package\u001b[39m.\u001b[39;49mlib_name)\n\u001b[1;32m    207\u001b[0m dev \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mcpu()\n\u001b[1;32m    209\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodule \u001b[39m=\u001b[39m runtime\u001b[39m.\u001b[39mcreate(package\u001b[39m.\u001b[39mgraph, lib, dev)\n",
      "File \u001b[0;32m/opt/tvm/python/tvm/rpc/client.py:159\u001b[0m, in \u001b[0;36mRPCSession.load_module\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_module\u001b[39m(\u001b[39mself\u001b[39m, path):\n\u001b[1;32m    147\u001b[0m     \u001b[39m\"\"\"Load a remote module, the file need to be uploaded first.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39m        The remote module containing remote function.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mLoadRemoteModule(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sess, path)\n",
      "File \u001b[0;32m/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py:237\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    225\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    226\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    227\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    228\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    236\u001b[0m ):\n\u001b[0;32m--> 237\u001b[0m     \u001b[39mraise\u001b[39;00m get_last_ffi_error()\n\u001b[1;32m    238\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    239\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  4: TVMFuncCall\n  3: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)>::AssignTypedLambda<tvm::runtime::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#5}>(tvm::runtime::{lambda(tvm::runtime::Module, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  2: tvm::runtime::RPCWrappedFunc::operator()(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) const\n  1: tvm::runtime::LocalSession::CallFunc(void*, TVMValue const*, int const*, int, std::function<void (tvm::runtime::TVMArgs)> const&)\n  0: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<TVMFuncCreateFromCFunc::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#2}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*) [clone .cold]\n  File \"/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 81, in cfun\n    rv = local_pyfunc(*pyargs)\n  File \"/opt/tvm/python/tvm/rpc/server.py\", line 79, in load_module\n    m = _load_module(path)\n  File \"/opt/tvm/python/tvm/runtime/module.py\", line 607, in load_module\n    return _ffi_api.ModuleLoadFromFile(path, fmt)\n  File \"/opt/tvm/python/tvm/_ffi/_ctypes/packed_func.py\", line 237, in __call__\n    raise get_last_ffi_error()\n  5: TVMFuncCall\n  4: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::runtime::Module (std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>::AssignTypedLambda<tvm::runtime::Module (*)(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)>(tvm::runtime::Module (*)(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&), std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  3: tvm::runtime::Module::LoadFromFile(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  1: tvm::runtime::CreateDSOLibraryObject(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)\n  0: tvm::runtime::DSOLibrary::Load(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&)\n  File \"../src/runtime/dso_library.cc\", line 119\nTVMError: \n---------------------------------------------------------------\nAn error occurred during the execution of TVM.\nFor more information, please see: https://tvm.apache.org/docs/errors.html\n---------------------------------------------------------------\n  Check failed: (lib_handle_ != nullptr) is false: Failed to load dynamic shared library /tmp/tmpmcrvfgqs/mod.so /tmp/tmpmcrvfgqs/mod.so: invalid ELF header"
     ]
    }
   ],
   "source": [
    "    onnx_runner = centerface_utils.CenterFaceOnnx(\"models/centerface-optimized.onnx\")\n",
    "    tvm_runner_fp32 = centerface_utils.CenterFaceTVM(\n",
    "        \"compiled_packages/centerface_autoscheduler_30000kt_fp32_llvm.tar\"\n",
    "    )\n",
    "    tvm_runner_fp16 = centerface_utils.CenterFaceTVM(\n",
    "        \"compiled_packages/centerface_autoscheduler_30000kt_fp16_llvm.tar\"\n",
    "    )\n",
    "    dummy_runner = centerface_utils.CenterFaceNoDetection()\n",
    "\n",
    "    # Change runners at will\n",
    "    demo = CameraDemo(tvm_runner_fp32)\n",
    "\n",
    "    demo.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38-tvm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fafdc0dff6d45f0157e08926e1aa6524d928be50516651d152e2c3e1c82f50f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
